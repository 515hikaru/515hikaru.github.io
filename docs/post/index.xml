<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on i was perfect</title>
    <link>tech.515hikaru.net/post/</link>
    <description>Recent content in Posts on i was perfect</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Mon, 09 Apr 2018 22:31:49 +0900</lastBuildDate>
    
	<atom:link href="tech.515hikaru.net/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Abstract Base Classes with Python</title>
      <link>tech.515hikaru.net/post/2018/04/09/python-abc-module/</link>
      <pubDate>Mon, 09 Apr 2018 22:31:49 +0900</pubDate>
      
      <guid>tech.515hikaru.net/post/2018/04/09/python-abc-module/</guid>
      <description>最近は Java っぽい Python を書いている。いや、僕は Java を書いたことがないので本当に Java っぽいのかはよくわからないのだけれど。
そんなわけで、 class の使い方について最近学びが多い。 Effective Python で読んだメタクラスとかが早くも役に立っている。ということで今日は抽象クラスの使い方なんかをまとめておく。
abc モジュール abc って言われた時、「アルファベットの最初の3文字がどうかした?」と思ったけれど、これは &amp;ldquo;Abstract Base Classes&amp;rdquo; の略。日本語にすると抽象基底クラス。
いつも使えるわけではないが、
 類似の処理をするクラス群がある クラスごとに固有のメソッドと共通のメソッドがある  という状況下において威力を発揮する。具体的には、
 共通のメソッド及びパブリックメソッドは統一して抽象基底クラスで定義  各種クラスは抽象基底クラスを継承して固有のメソッドのみを実装する   とすることでクラスが増えても固有のメソッドにのみ注力すればよい。
以下に具体例を用いてどんな利点があるのかを書くが、正確なことは公式ドキュメントを見るべきだ。この記事書く必要なくない?
具体例 動物を鳴かせる たとえばよくある例で Dog というクラスに鳴く(bark)というメソッドを定義することを考える1。
class Dog(object): def bark(self): print(&#39;わんわん&#39;)  こんなふうに定義して使っていたところ、動物は犬だけじゃなく猫も必要だということがわかった。ということで猫も定義しよう。
class Cat(object): def meow(self): print(&#39;にゃー&#39;)  この実装の問題 とここで次のようなユースケースで早速困る。
def make_sound(animal): animal.bark() # animal が Dog だったらOK, Cat だったらエラー  ということで、動物の鳴き声メソッドは統一するべきだとわかる。ここでは sound としよう。</description>
    </item>
    
    <item>
      <title>DjangoのFormオブジェクトの使い方Tips</title>
      <link>tech.515hikaru.net/post/2017/12/28/how-to-use-django-form-obj/</link>
      <pubDate>Thu, 28 Dec 2017 00:00:00 +0900</pubDate>
      
      <guid>tech.515hikaru.net/post/2017/12/28/how-to-use-django-form-obj/</guid>
      <description>Django とは Django とは, Python の Web フレームワークです. Ruby でいうところの Rails 1に相当するフレームワークで, Git ホスティングサービスのBitbucket や最近「インスタ映え」で話題の Instagram にも利用されています2.
この記事を書いている人も Django を使って Web アプリを作ったり作らなかったりしています.
Form オブジェクト Django には当然いくつもの機能があるのですが, 筆者が一番ググるのが表題の Form オブジェクトについてです.
Form オブジェクトは, 処理をするのに必要十分なデータが含まれているか, 不適切なデータが入っていないかをチェック(Validation)したり, HTML を自動生成したり, データベースの定義から Form を生成したりといろんなことができます.
いろんなことができるので, こういうことできないかな? と思った時に StackOverflow をたくさん漁るのは僕だけではないはず&amp;hellip;
そんなわけで今まで StackOverflow で得てきた知見のいくつかを書いておくことにしました. 体系的な解説というよりは, Tips 寄せ集めとして, やりたいこととその方法を書いていく感じです.
Form のフィールドを可変にしたい 複数入力可能なフィールドを作りたいことはよくあるでしょう. クラス変数を動的に増やせばいいのでコンストラクタで増やします.
以下は value_i という名前のフィールドを可変にする方法です.
from django import forms class SampleForm(forms.Form): def __init__(self, num, *args, **kwargs): super().__init__(*args, **kwargs) for i in range(num): self[&#39;value_{}&#39;.</description>
    </item>
    
    <item>
      <title>なぜデータの前処理は難しいのか</title>
      <link>tech.515hikaru.net/post/2017/12/09/why-data-preprocessing-is-difficult/</link>
      <pubDate>Sat, 09 Dec 2017 00:00:00 +0900</pubDate>
      
      <guid>tech.515hikaru.net/post/2017/12/09/why-data-preprocessing-is-difficult/</guid>
      <description>データ分析の業務工程のうち、半分以上は前処理で占められているという話がある。おそらく業界の人間であれば必ず一度は聞き、実際に実感する話であり、それ以外の人でも興味がある人であればこの話を聞いたことがあるだろう。
しかし実際のところなぜデータの前処理でそこまで時間を食うのか、あるいは何がそんなに難しいのかを解説されたことがほとんどない気がする1。ということで、1年ほど仕事をしてきた私見を書いてみようと思う。あくまでも個人の経験と偏見に基づいた話なのでこれが「普遍的な難しさである」と主張する気はない。しかし、なんとなく「似たようなこと」は日本中のそこかしこで起きているんじゃないかと根拠もなく思ってはいる。
この記事は個人の見解であり、筆者が所属する組織・団体などの意見を代表するものではありません2。
前提 繰り返しになるが、データの前処理で筆者がよく難しいと思うことを思いつく順に書いていこうと思う。
ただ、本論に入る前に少しだけ筆者のバックグラウンドを説明しておく。筆者は基本的にはエクセルシートやcsvファイルを受け取って、そのデータを用いて予測モデルを作ったり、先日も記事にした類似度計算をすることでリコメンドシステムを実装したりするのが仕事である。どの業務をする上でも、csvファイルから必要な列のみ取り出したり、データの形式を変えたりするなど前処理のプロセスは必ず生じる。また、画像の前処理の経験はなく、テキストデータの前処理しか経験がない。
データの不備の検知しづらさ 少し想像してみてほしい。Excelファイルに10,000人分の身長が記録されていたとする。このとき、身長が [cm] という単位で記録されるべきところ、入力者が誤って [mm] で入力してしまっている。どうやって探すだろうか?
予め「このデータには絶対に上記のような不備がある」とわかっているのであればそれを発見するのはそこまで難しい話ではない。大きい順、あるいは小さい順にソートして人間としては(cmでの数値だとしたとき)身長が高すぎる/低すぎるものを見つければいい。可視化して明らかなハズレ値を調べるというのも手だろう。
しかし、残念ながら経験上いきなりデータの不備を疑うことは稀だ。時間に追われていることも多いし、いきなり前処理のプログラムを書いてしまうだろう。データベースに登録したり、あるいは別のcsvファイルと結合したりする。プログラムは異常な値を含んでいても「回ってしまうから」だ。
時間が十分にあれば事前のチェックを時間をとってできるかもしれないが、時間がない場合は見逃されてしまうだろう。上の例では身長のみだったので外れ値を探すのは難しくなかったかもしれないが、身長、体重、年齢、血液型、住んでいる都道府県などなどデータが数十、数百あった場合。異常な値をいかにみつけるか?すべて手作業でやるしかないのなら、その処理がそのプロジェクトの成功にどれほど寄与するだろうか?
データの変更によるプログラムの変更 データその1を前処理したスクリプトで、データその2を前処理することがよくある。最初から大量のデータを扱うことは稀で、基本的には少ないデータで始めて徐々に多くしていったり、精度向上のため変数の変更、追加、削除をすることがあるからだ。
しかし、このときデータその1を処理したスクリプトを一切変更せずその2を前処理できることは極めて稀だと言っていいと思う。具体的に何が起きるかを例で示そう。
具体例 かんたんのため小さいデータセットで書く。
    foo bar     1 1 2   2 3 4   3 5 6    こんなデータがあるとして foo 列と bar 列を標準化したい3とする。さっと書くと次のようなコードになる(上のデータが data1.csv に書き出されているものとする)。
import pandas as pd from sklearn.preprocessing import StandardScaler d = pd.read_csv(&#39;data1.csv&#39;) sc = StandardScaler() print(sc.fit_transform(d)) # 実行結果 # [[-1.</description>
    </item>
    
  </channel>
</rss>