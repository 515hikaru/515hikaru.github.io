---
title: "機械学習PoCプロジェクトにおけるコード品質"
date: 2019-07-06T17:37:22+09:00
draft: false
tags: ["Machine Learning"]
---

# コード品質とPoC

あまり語られないが、個人的に重要視しているもののひとつに機械学習モデルの精度検証時のコードの品質がある。個人的に好きなテーマだが、機械学習の精度検証における最重要KPIは当然モデルの予測精度であって、コードカバレッジでも保守性でもなんでもない。むしろPoCのコードを本番にそのまま適用するなんてあり得ないのだから、品質を高めたところでそんなに意味がないのではないか、そんな風に思う人さえいるだろう。


~~~
「こんな実験コード書きました!
  前処理も標準化などの処理もfit()を呼ぶだけでよしなにやってくれますし、
  データを読み込む関数と、自前の前処理クラスだけテストすれば他のクラスは
  テストをする必要がありません!
  だから各クラスの単体テストがあればほとんど確実に実験にミスがないと断言できます!!」

「でもこのプロジェクト、精度出てないよね」

                糸冬
        --------------------
          制作・著作 ＮＨＫ
~~~

という話なので、コードの品質を強く気にしている人は正直そんなにいないだろう、とわたしは思っている。あまりケアしすぎても困る事柄なことは事実だからだ。

しかし一方で、実験のコードはテストをしなくてもいいほど簡単であるとも思えない。というか、学習のコードはおそらくPython、R、Juliaなどの動的型付け言語で書かれることがほとんどだろう。テストをしないで正確性を担保することは事実上不可能といってもいい。

推論結果や予測結果といったものをテストすることにそこまで意味はない[^1]と思うが、学習や推論の過程でデータを変形させる(m×n 行列を k×l 行列にしたり、データの中身を特定の規則にそって変えたりなど)することには意味があるし、その正確性・再現性は担保されていないと意図どおりではない学習データで実験を行ったりしてしまう。

[^1]: ある特定のバージョンから学習結果が変わらないことをテストする意味があるケースはもしかしたら存在するかもしれない。

そんな実験での一般的なトラブルを減らすため、取れるアプローチはいくつもあると思う。その中でもわたしは「コード品質を高める」ことがアプローチの一つだと思っている。

# 変遷

結論をいきなり書く前に、何を経験して何を考えて実践してきたかを書き出してみる。

なお背景として、わたしは自社サービス会社では働いたことがなく、クライアントからなんらかの形でデータをもらい(だいたいCSVかExcel)、それをPythonなどでメモリに読み込み、コードを書いていた。

## 初期のプロジェクト

実験におけるコード特有の問題というものをまだ意識していなかった頃の話。書き出すのは非常に恥ずかしいが、わたしもこんな感じで仕事をしていたのだと振り返ってみる。

- データ整形(前処理)、特徴量の変換・抽出・学習・評価、どのコードもJupyter Notebook上に書く
- 変数はグローバル、モジュール化も一切なされていない
- 関数さえほぼない
- 再現性もない
- バージョン管理ができない(git commit はしていたかもしれないけど事実上できていない)

とないないづくし。さすがにこんな地獄は見ておれん。

## 複数回経験後のプロジェクト

こんな状態を長時間労働することで乗り越えてきたわけだが、さすがにやってられないので自分のひとりプロジェクトのときに考え直すことにした。

- 複数のファイルに似たようなコードが発生する

## 推薦アプリを作るプロジェクト

アプリを作る、ということを考えた。

## 最新のプロジェクト

PoCでモデルづくりだけ。

# 次やりたいこと

# まとめ
