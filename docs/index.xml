<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>i was perfect</title>
    <link>/</link>
    <description>Recent content on i was perfect</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Sat, 21 Apr 2018 21:52:01 +0900</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>情報共有ツールの導入の反省</title>
      <link>/post/2018/04/21/share-is-important/</link>
      <pubDate>Sat, 21 Apr 2018 21:52:01 +0900</pubDate>
      
      <guid>/post/2018/04/21/share-is-important/</guid>
      <description> 社内Wikiの導入 最近、業務でいわゆる社内Wikiサービスの導入をした。導入したサービスは esa.ioである。読み方は「エサ」だ。
弊社1ではしばらく情報共有のための場がなく、利用する言語の処理系のインストールも、利用するテキストエディタの標準的な設定方法も、散々利用している Docker の使い方も各々がググって各々がそれっぽくやる、という状況に陥っていた。
そんな状態を改善したいと、この数ヶ月で得た信頼を武器に自分の要望を適切な場所に直談判したり、上司に助けられたりして、とりあえずツールの導入はした。ここからが勝負だが、とりあえずできたものはできたのでホッとしている。
ここでは、なぜできたのかを少し考えたい。
組織の土壌や文化を塗り替える 残念ながら、あらゆる事情で弊社にはあからさまによくない文化がはびこっていた。会議の議事録を取る文化がない(ので言った、言わない問題がしばしば起こる)とか、議事録の共有が Slack で行われる(無料版を利用しているから消える!)とかが筆頭だ。これは現在もなんやかんや残っている課題だ。
こうした状況の社内であらゆる障害を乗り越える、組織の土壌、文化を塗り替えていく努力をするのは思っているよりも骨が折れることだ。
しかし、1年以上前から画策していた僕にとっては、情報共有ツールを導入するのにあんだけ苦労したのに、いざ達成するとあっけなく終わった、という気分だ。それには複数の事情がある。
中途採用の増加による社内Wiki経験者の増加 中途採用が多いのもあり、「前の会社にはあったもの」が「弊社にはない」という意見が見られるようになった。
わたしもアルバイトなどでBacklogを使っている会社で働いたり、サークルでMedia Wikiを利用した経験があるので、情報共有ツールなんて「あって当然のもの」というふうに1年前から思っていた。弊社の場合は「あって当然」と思う人のほうが数が少なかったのか、なかなか導入の必要性の議論に行くことがなかった、と推測している。
いずれにせよ、組織の構成員が変わり、「当たり前」の基準が総合的には高くなっていっているのだと思う。これは良いことだ。
勉強会などの文化の醸成 弊社では自主的な社内勉強会は勃興しては廃れを繰り返していた。結局社内のニーズを汲めなかったのだろう。しかし経営陣から直々に勉強会を毎週するように司令が下り、責任者を立てて毎週決まった時間に勉強会が必ず行われるように変わった。
この習慣は間違いなく「自分がやったことを共有する」という文化に寄与している。そして、この文化が適度に醸成されてきたからこそ、社内情報共有ツールが受け入れられることになったのだと思う2。
勝因 勝因は「タイミング」だと思う。自分の目的と別の誰かの目的とが実は合致していて、経営陣は勉強会という形で、わたしはツールの導入という形で達成しようとしていた。前者と後者は相互に補いあえるものなので、話も通りやすかった。
1年前からやりたかったのでかなり遅くはなったが、間接的にも直接的にも経営陣の力を借りることで実現に向かった。そして経営陣は情報を共有するという文化の醸成に寄与してくれた。今後もこの文化がエンジニアのものに留まらず、全社の文化になっていくといいなと少し思っている。
自分の意見を通すために よくわたしが考えていることだが、組織で不満がある場合に「自分の直属の上司」とか「経営陣への直談判」とかは初手としてはあまり意味がないか、むしろ自分の思惑とは外れていく可能性が高い。
まずは自分の賛同者が組織の中にどれくらいいるのかを確認するところから始めるべきだ。自分と同じ考えの人、自分と同じ意識を持つ人がいなければまだタイミングではないということだと諦めてしまおう。自分が周りを説得しても実る可能性はかなり低い。
それよりかは粛々としたがって自分の周りからの信頼を厚くすることに注力するべきだ3。
自分の味方を増やし、そして実行者や権力者の直下にいる人に提案・交渉をする。ここで実行者や権力者に直ではあまり言わない(言うなら1対1の対面の時に限る)。理由は、実行者や権力者の側近のほうがより伝えやすく整備した形で伝えてくれるからだ。あと単純に側近の話のほうがよく聞くだろう、というのもある。
あとは実行者がよしなにしてくれる。事が多い。大切なことは普段の業務では不平や不満を表に出さないことだ。通常時に不平不満を表に出すことは会社の士気に関わり目をつけられる可能性が高い。ネガティブなことを言う場所には十分に気を使うべきだ。
&amp;hellip;というようなことばかり考えているせいか、最近すごい疲れている。こんなこと考えないで仕事できるのが一番いいのだが。。。
 諸般の事情で名前は出さないが、機械学習系スタートアップベンチャー企業のひとつとだけ書いておく。 [return] タイミングが被ったのは完全に偶然だが。 [return] わたしは気に入らないルールほど絶対に守るようにしている。ルールを守らない人間がルールに文句を言っても説得力を失ってしまうからだ。 [return]   </description>
    </item>
    
    <item>
      <title>Dockerってべんり</title>
      <link>/post/2018/04/12/docker-is-useful/</link>
      <pubDate>Wed, 11 Apr 2018 23:34:30 +0900</pubDate>
      
      <guid>/post/2018/04/12/docker-is-useful/</guid>
      <description>この記事は何かの解説、というよりは最近の感想である。
やっと Docker って便利だなと思えるようになってきた。一年近く前から Docker を避けるようになり、最近業務の都合で(上司が採用したから!)Dockerを使うことになったのだが、きちんとお膳立てされていている状態で使い始めればそんなに厄介なものでもないな、と思い始めた。そんなにすごい使い方はしていないが。
よいところ 実行環境の用意のしやすさ DBに格納されたデータを取得して整形するメソッドを実装したので、当然テストしたいわけだが、単体テストはともかく結合テストが厄介。あらかじめ DB を用意する必要がある。
しかし、手動でいいのであれば1、下記のようなコマンドを事前に叩いておけば DB が自動で立ち上がる(例では MongoDB を利用)。
$ docker run -p 27017:27017 mongo:3.4  この 1 コマンドでアプリケーションと MongoDB の結合テストを実施することが可能になる2。
はやい はやい。開発環境として使うなら Vagrant のほうが好きな僕だけど、このはやさだけは Docker の(ひいてはコンテナ技術の)圧勝だ。長い Dockerfile のビルドもキャッシュを使えばわりと一瞬だし、止める、消す、再度生成するなど何度も繰り返す処理がはやいので、ストレスがない。空き時間にお菓子を食べすぎてしまうこともない。
結局最近 Vagrant を使っていない3のはこのはやさのせいだと言っても過言ではない。
よくないところ 難しい コンテナ技術のことをよく知らないので、雑いことしか言えないのだけど、普通に Docker は難しいと思う。特に Linux に不慣れな人は悪戦苦闘しながら利用していたりする。
個人的にはエンジニアでさえそうなのだから、非エンジニアの方々の PC でアプリケーションを動かしてもらうときに、非エンジニアの方々の PC に Docker をインストールするのとかどうなのよ? とか思ってしまう。が一方でそこで Docker を使わないともっと面倒くさいとかいう現象も発生しそう4なので一概には言えなかったりする。
やっぱりよくわかんない 一年前の記憶だが、 Docker にはかなり苦しめられた記憶がある。主に docker-compose がわからなかったせいなのだが。今ではあまりそう思わないが、当時は Docker 使うとここまで大変になるなら、ホストにきちんとインストールしたほうがよくない? と思ったものだ。
その時の記憶や経験が完全に払拭されたわけではない5。だから「よくわからないから避けたい」という気持ちもまだある。しかしこれも経験の1つかと諦めてもいる。
今後の活用の模索 最近は個人でも Docker を使おうかと少し考え始めている。例えば、Haskell のインタプリタを利用するのに Docker Hub からダウンロードしたイメージを利用した。</description>
    </item>
    
    <item>
      <title>Abstract Base Classes with Python</title>
      <link>/post/2018/04/09/python-abc-module/</link>
      <pubDate>Mon, 09 Apr 2018 22:31:49 +0900</pubDate>
      
      <guid>/post/2018/04/09/python-abc-module/</guid>
      <description>最近は Java っぽい Python を書いている。いや、僕は Java を書いたことがないので本当に Java っぽいのかはよくわからないのだけれど。
そんなわけで、 class の使い方について最近学びが多い。 Effective Python で読んだメタクラスとかが早くも役に立っている。ということで今日は抽象クラスの使い方なんかをまとめておく。
abc モジュール abc って言われた時、「アルファベットの最初の3文字がどうかした?」と思ったけれど、これは &amp;ldquo;Abstract Base Classes&amp;rdquo; の略。日本語にすると抽象基底クラス。
いつも使えるわけではないが、
 類似の処理をするクラス群がある クラスごとに固有のメソッドと共通のメソッドがある  という状況下において威力を発揮する。具体的には、
 共通のメソッド及びパブリックメソッドは統一して抽象基底クラスで定義  各種クラスは抽象基底クラスを継承して固有のメソッドのみを実装する   とすることでクラスが増えても固有のメソッドにのみ注力すればよい。
以下に具体例を用いてどんな利点があるのかを書くが、正確なことは公式ドキュメントを見るべきだ。この記事書く必要なくない?
具体例 動物を鳴かせる たとえばよくある例で Dog というクラスに鳴く(bark)というメソッドを定義することを考える1。
class Dog(object): def bark(self): print(&#39;わんわん&#39;)  こんなふうに定義して使っていたところ、動物は犬だけじゃなく猫も必要だということがわかった。ということで猫も定義しよう。
class Cat(object): def meow(self): print(&#39;にゃー&#39;)  この実装の問題 とここで次のようなユースケースで早速困る。
def make_sound(animal): animal.bark() # animal が Dog だったらOK, Cat だったらエラー  ということで、動物の鳴き声メソッドは統一するべきだとわかる。ここでは sound としよう。</description>
    </item>
    
    <item>
      <title>DjangoのFormオブジェクトの使い方Tips</title>
      <link>/post/2017/12/28/how-to-use-django-form-obj/</link>
      <pubDate>Thu, 28 Dec 2017 00:00:00 +0900</pubDate>
      
      <guid>/post/2017/12/28/how-to-use-django-form-obj/</guid>
      <description>Django とは Django とは, Python の Web フレームワークです. Ruby でいうところの Rails 1に相当するフレームワークで, Git ホスティングサービスのBitbucket や最近「インスタ映え」で話題の Instagram にも利用されています2.
この記事を書いている人も Django を使って Web アプリを作ったり作らなかったりしています.
Form オブジェクト Django には当然いくつもの機能があるのですが, 筆者が一番ググるのが表題の Form オブジェクトについてです.
Form オブジェクトは, 処理をするのに必要十分なデータが含まれているか, 不適切なデータが入っていないかをチェック(Validation)したり, HTML を自動生成したり, データベースの定義から Form を生成したりといろんなことができます.
いろんなことができるので, こういうことできないかな? と思った時に StackOverflow をたくさん漁るのは僕だけではないはず&amp;hellip;
そんなわけで今まで StackOverflow で得てきた知見のいくつかを書いておくことにしました. 体系的な解説というよりは, Tips 寄せ集めとして, やりたいこととその方法を書いていく感じです.
Form のフィールドを可変にしたい 複数入力可能なフィールドを作りたいことはよくあるでしょう. クラス変数を動的に増やせばいいのでコンストラクタで増やします.
以下は value_i という名前のフィールドを可変にする方法です.
from django import forms class SampleForm(forms.Form): def __init__(self, num, *args, **kwargs): super().__init__(*args, **kwargs) for i in range(num): self[&#39;value_{}&#39;.</description>
    </item>
    
    <item>
      <title>なぜデータの前処理は難しいのか</title>
      <link>/post/2017/12/09/why-data-preprocessing-is-difficult/</link>
      <pubDate>Sat, 09 Dec 2017 00:00:00 +0900</pubDate>
      
      <guid>/post/2017/12/09/why-data-preprocessing-is-difficult/</guid>
      <description>データ分析の業務工程のうち、半分以上は前処理で占められているという話がある。おそらく業界の人間であれば必ず一度は聞き、実際に実感する話であり、それ以外の人でも興味がある人であればこの話を聞いたことがあるだろう。
しかし実際のところなぜデータの前処理でそこまで時間を食うのか、あるいは何がそんなに難しいのかを解説されたことがほとんどない気がする1。ということで、1年ほど仕事をしてきた私見を書いてみようと思う。あくまでも個人の経験と偏見に基づいた話なのでこれが「普遍的な難しさである」と主張する気はない。しかし、なんとなく「似たようなこと」は日本中のそこかしこで起きているんじゃないかと根拠もなく思ってはいる。
この記事は個人の見解であり、筆者が所属する組織・団体などの意見を代表するものではありません2。
前提 繰り返しになるが、データの前処理で筆者がよく難しいと思うことを思いつく順に書いていこうと思う。
ただ、本論に入る前に少しだけ筆者のバックグラウンドを説明しておく。筆者は基本的にはエクセルシートやcsvファイルを受け取って、そのデータを用いて予測モデルを作ったり、先日も記事にした類似度計算をすることでリコメンドシステムを実装したりするのが仕事である。どの業務をする上でも、csvファイルから必要な列のみ取り出したり、データの形式を変えたりするなど前処理のプロセスは必ず生じる。また、画像の前処理の経験はなく、テキストデータの前処理しか経験がない。
データの不備の検知しづらさ 少し想像してみてほしい。Excelファイルに10,000人分の身長が記録されていたとする。このとき、身長が [cm] という単位で記録されるべきところ、入力者が誤って [mm] で入力してしまっている。どうやって探すだろうか?
予め「このデータには絶対に上記のような不備がある」とわかっているのであればそれを発見するのはそこまで難しい話ではない。大きい順、あるいは小さい順にソートして人間としては(cmでの数値だとしたとき)身長が高すぎる/低すぎるものを見つければいい。可視化して明らかなハズレ値を調べるというのも手だろう。
しかし、残念ながら経験上いきなりデータの不備を疑うことは稀だ。時間に追われていることも多いし、いきなり前処理のプログラムを書いてしまうだろう。データベースに登録したり、あるいは別のcsvファイルと結合したりする。プログラムは異常な値を含んでいても「回ってしまうから」だ。
時間が十分にあれば事前のチェックを時間をとってできるかもしれないが、時間がない場合は見逃されてしまうだろう。上の例では身長のみだったので外れ値を探すのは難しくなかったかもしれないが、身長、体重、年齢、血液型、住んでいる都道府県などなどデータが数十、数百あった場合。異常な値をいかにみつけるか?すべて手作業でやるしかないのなら、その処理がそのプロジェクトの成功にどれほど寄与するだろうか?
データの変更によるプログラムの変更 データその1を前処理したスクリプトで、データその2を前処理することがよくある。最初から大量のデータを扱うことは稀で、基本的には少ないデータで始めて徐々に多くしていったり、精度向上のため変数の変更、追加、削除をすることがあるからだ。
しかし、このときデータその1を処理したスクリプトを一切変更せずその2を前処理できることは極めて稀だと言っていいと思う。具体的に何が起きるかを例で示そう。
具体例 かんたんのため小さいデータセットで書く。
    foo bar     1 1 2   2 3 4   3 5 6    こんなデータがあるとして foo 列と bar 列を標準化したい3とする。さっと書くと次のようなコードになる(上のデータが data1.csv に書き出されているものとする)。
import pandas as pd from sklearn.preprocessing import StandardScaler d = pd.read_csv(&#39;data1.csv&#39;) sc = StandardScaler() print(sc.fit_transform(d)) # 実行結果 # [[-1.</description>
    </item>
    
  </channel>
</rss>